{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PGGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Progressive Growing of GANs For Improved Quality, Stability and Variation\n",
        "\n",
        "## Abstract\n",
        "\n",
        "무엇을 해냈나?\n",
        "\n",
        "new training methodology for GAN. ***G와 D를 서서히 키워가는 것***\n",
        "\n",
        "→ training 속도 ↑ & 안정화\n",
        "\n",
        "생성 이미지의 variation을 증가시키는 simple way\n",
        "\n",
        "GAN의 결과를 evalutate할 새로운 측정법\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Generative Methods \n",
        "\n",
        "ex) Autoregressive models, Variational Autoencoders (VAE), Generative Adversarial Networks (GAN)\n",
        "\n",
        "- Autoregressive models\n",
        "    \n",
        "    ex) PixelCNN\n",
        "    \n",
        "    선명한 이미지를 만들지만 검증이 느리고 곧바로 conditional distribution을 만들기 때문에 latent representation이 없음 → 응용가능성 ↓\n",
        "    \n",
        "- VAE\n",
        "    \n",
        "    train하기 쉽지만 blurry results\n",
        "    \n",
        "- GAN\n",
        "    \n",
        "    선명한 이미지를 만들지만 small resolution(저해상도), limited variation에서만\n",
        "    \n",
        "    더 높은 해상도가 될수록 \n",
        "    \n",
        "    생성된 이미지가 D에게 들킬 확률 ↑\n",
        "    \n",
        "    메모리의 한계 → smaller minibatches를 사용해야함 → train 불안정함\n",
        "    \n",
        "\n",
        "이 중 GAN의 방법을 더 발전시켜 고화질의 이미지를 생성할 수 있다!\n",
        "\n",
        "## Progressive Growing of GANs\n",
        "\n",
        "<img src=\"https://user-images.githubusercontent.com/66329748/169148464-e9beea3b-9469-4435-a3b0-1c2f6aca1c7c.png\">\n",
        "\n",
        "![https://miro.medium.com/max/1400/1*tUhgr3m54Qc80GU2BkaOiQ.gif](https://miro.medium.com/max/1400/1*tUhgr3m54Qc80GU2BkaOiQ.gif)\n",
        "\n",
        "저해상도의 image에서 시작해, network에 layer를 추가하여 해상도 ↑\n",
        "\n",
        "ex) 4X4 layer에서 충분히 학습이 잘 되었다고 생각하면 해상도를 올려서 8X8에서 학습\n",
        "\n",
        "→ large-scale structure (전반적인 구도, 전반적인 형태) 부터 잡아내고 finer scale detail로 shift attention\n",
        "\n",
        "G와 D가 서로 거울상 & 동시에 grow\n",
        "\n",
        "새로운 layer가 추가될 때, smooth하게 fade in → 이미 잘 학습된 기존의 layer들의 sudden shock을 방지\n",
        "\n",
        "![a에서 b로 갈 때 16X16으로 만들어낸 이미지를 단순히 크기만 2배로 키움 (이미지 1)\n",
        "32 X 32에서 이미지를 만들어냄 (이미지 2)\n",
        "(1-a) * (이미지 1) + a * (이미지 2) = 생성 이미지\n",
        "a는 0에서 1로 점차 증가. 즉, 이전 layer의 영향력은 점점 작아지고 새로운 layer의 영향은 점점 커짐](https://user-images.githubusercontent.com/66329748/169148651-6c3d5622-1cae-413c-8846-99c0378139e6.png)\n",
        "\n",
        "a에서 b로 갈 때 16X16으로 만들어낸 이미지를 단순히 크기만 2배로 키움 (이미지 1)\n",
        "32 X 32에서 이미지를 만들어냄 (이미지 2)\n",
        "(1-a) * (이미지 1) + a * (이미지 2) = 생성 이미지\n",
        "a는 0에서 1로 점차 증가. 즉, 이전 layer의 영향력은 점점 작아지고 새로운 layer의 영향은 점점 커짐\n",
        "\n",
        "progressive training의 몇가지 장점\n",
        "\n",
        "- 작은 이미지 생성은 stable → 거기부터 해상도를 점점 키워가는 것이 latent vector로부터 만들어내는 것보다 much simpler question\n",
        "    \n",
        "    WGAN-GP Loss 나 LSGAN Loss를 사용\n",
        "    \n",
        "- training time ↓\n",
        "    \n",
        "    대부분의 iteration이 낮은 해상도일 때 일어남\n",
        "    \n",
        "    약 2~6배 빠름\n",
        "    \n",
        "\n",
        "## Increasing Variation Using Minibatch Standard Deviation\n",
        "\n",
        "GAN은 training data의 부분적인 variation만 capture하는 경향이 있다 → 해결책 : “minibatch discrimination” (Salimans et al. “Improved techniques for training GANs”. 2016)\n",
        "\n",
        "individual images가 아니라 minibatch 단위에서 feature statistics를 계산 → 생성이미지와 train 이미지가 similar statistics 갖게함\n",
        "\n",
        "minibatch layer를 Discriminator 끝에 넣음\n",
        "\n",
        "이 논문에서 제시하는 더 simple한 solution\n",
        "\n",
        "minibatch의 각 spatial location의 각 feature들의 표준편차를 계산 (N X C X H X W → C X H X W)\n",
        "\n",
        "spatial location들과 모든 feature에 대한 이 추정치들의 평균을 계산하여 single value로 만듦 (C X H X W → 1 X H X W)\n",
        "\n",
        "값을 복제하고 모든 spatial location과 모든 feature들에 연결하여 하나의 추가적인 feature map을 생성\n",
        "\n",
        "이 layer는 D의 어디든 들어갈 수 있지만 끝부분에 넣는게 best\n",
        "\n",
        "## Normalization in Generator and Discriminator\n",
        "\n",
        "GAN은 G와 D의 분필요한 경쟁으로 인해 발생하는 escalation of signal magnitude에 취약 \n",
        "\n",
        "→ 보통은 이런 문제점을 해결하기 위해 Batch Normalization 사용 → Covariance Shift 방지\n",
        "\n",
        "→ 하지만 이 논문에서는 Covariance Shift를 방지할 필요 X \n",
        "\n",
        "> *we have not observed that to be an issue in GANs*\n",
        "> \n",
        "\n",
        "→ Different Approach\n",
        "\n",
        "### Equalized Learning Rate\n",
        "\n",
        "기존의 신중한 weight initialization 대신, 단순히 N(0, 1) initialization 사용 & runtime 중에 weight scale\n",
        "\n",
        "![스크린샷 2022-05-19 오전 3.10.56.png](https://user-images.githubusercontent.com/66329748/169148759-582ee2ac-a548-4381-8d89-eb42eea58fbc.png)\n",
        "\n",
        "$w_i$는 weight, $c$는 Kaiming He Initialization의 per-layer normalization constant\n",
        "\n",
        "기존의 RMSProp이나 Adam과 같은 adaptive SGD 방식은 어떤 parameter들이 더 넓은 dynamic range를 가지면 적응하는데 시간이 오래 걸림\n",
        "\n",
        "이 논문에서는 dynamic range를 모든 weight에 대해 같게 함으로써 learning speed도 동일하게 함\n",
        "\n",
        "### Pixelwise Feature Vector Normalization in Generator\n",
        "\n",
        "위에서 언급한 Different Approach → “local response normalization” 사용\n",
        "\n",
        "G의 각 convolutional layer가 끝날 때, 각 pixel의 feature vector를 unit length별로 normalize\n",
        "\n",
        "→ G를 harm하지 X, 결과를 변형시키지 X, 단지 escalation of signal magnitude 방지\n",
        "\n",
        "## Mulit-Scale Statistical Similarity for Assessing GAN Results\n",
        "\n",
        "GAN의 결과를 다른 것과 비교하려면 많은 수의 이미지들을 분석해야함 → 힘듦\n",
        "\n",
        "MS-SSIM이라는 방법이 있지만 단점들이 많이 존재 (작은 변화에 반응 X, train data와의 유사도 관점에서 이미지의 quality를 직접적으로 평가 X)\n",
        "\n",
        "이 논문에서는 Laplacian Pyramid로부터 나오는 local image patch들의 분포간 multiscale statistical similarity를 통해 분석\n",
        "\n",
        "1. Training set과 Generated set에서 local image patch들을 얻음\n",
        "2. 둘 사이의 SWD(Sliced Wasserstein Distance)를 계산하여 statistical similarity를 estimate\n",
        "\n",
        "작은 W distance는 local image patch들의 분포가 비슷하다는 것을 의미\n",
        "\n",
        "# 모델 구조\n",
        "\n",
        "![Untitled](https://user-images.githubusercontent.com/66329748/169148853-414b968b-1255-4e5d-a3b9-a67b51603bfe.png)\n",
        "\n",
        "![Untitled](https://user-images.githubusercontent.com/66329748/169148859-1170b239-970e-4161-ae03-030bcbad22db.png)"
      ],
      "metadata": {
        "id": "9DJr-u2gznKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/pytorch_GAN_zoo.git"
      ],
      "metadata": {
        "id": "SlPsnsnK1Z6v",
        "outputId": "0991f247-c4e8-4230-bb02-628f4b87c158",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch_GAN_zoo'...\n",
            "remote: Enumerating objects: 1523, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 1523 (delta 17), reused 21 (delta 13), pack-reused 1495\u001b[K\n",
            "Receiving objects: 100% (1523/1523), 2.06 MiB | 11.47 MiB/s, done.\n",
            "Resolving deltas: 100% (977/977), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Generator 부분\n",
        "    \n",
        "    def addScale(self, depthNewScale):\n",
        "        r\"\"\"\n",
        "        Add a new scale to the model. Increasing the output resolution by\n",
        "        a factor 2\n",
        "        Args:\n",
        "            - depthNewScale (int): depth of each conv layer of the new scale\n",
        "        \"\"\"\n",
        "        depthLastScale = self.scalesDepth[-1]\n",
        "\n",
        "        self.scalesDepth.append(depthNewScale)\n",
        "\n",
        "        self.scaleLayers.append(nn.ModuleList())\n",
        "\n",
        "        self.scaleLayers[-1].append(EqualizedConv2d(depthLastScale,\n",
        "                                                    depthNewScale,\n",
        "                                                    3,\n",
        "                                                    padding=1,\n",
        "                                                    equalized=self.equalizedlR,\n",
        "                                                    initBiasToZero=self.initBiasToZero))\n",
        "        self.scaleLayers[-1].append(EqualizedConv2d(depthNewScale, depthNewScale,\n",
        "                                                    3, padding=1,\n",
        "                                                    equalized=self.equalizedlR,\n",
        "                                                    initBiasToZero=self.initBiasToZero))\n",
        "\n",
        "        self.toRGBLayers.append(EqualizedConv2d(depthNewScale,\n",
        "                                                self.dimOutput,\n",
        "                                                1,\n",
        "                                                equalized=self.equalizedlR,\n",
        "                                                initBiasToZero=self.initBiasToZero))\n",
        "\n",
        "    def setNewAlpha(self, alpha):\n",
        "        r\"\"\"\n",
        "        Update the value of the merging factor alpha\n",
        "        Args:\n",
        "            - alpha (float): merging factor, must be in [0, 1]\n",
        "        \"\"\"\n",
        "\n",
        "        if alpha < 0 or alpha > 1:\n",
        "            raise ValueError(\"alpha must be in [0,1]\")\n",
        "\n",
        "        if not self.toRGBLayers:\n",
        "            raise AttributeError(\"Can't set an alpha layer if only the scale 0\"\n",
        "                                 \"is defined\")\n",
        "\n",
        "        self.alpha = alpha"
      ],
      "metadata": {
        "id": "2Rd8Il_T8chh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def updateAlphaJumps(self, nJumpScale, sizeJumpScale):\n",
        "        \"\"\"\n",
        "        Given the number of iterations between two updates of alpha at each\n",
        "        scale and the number of updates per scale, build the effective values of\n",
        "        self.maxIterAtScale and self.alphaJumpVals.\n",
        "        Args:\n",
        "            - nJumpScale (list of int): for each scale, the number of times\n",
        "                                        alpha should be updated\n",
        "            - sizeJumpScale (list of int): for each scale, the number of\n",
        "                                           iterations between two updates\n",
        "        \"\"\"\n",
        "\n",
        "        n_scales = min(len(nJumpScale), len(sizeJumpScale))\n",
        "\n",
        "        for scale in range(n_scales):\n",
        "\n",
        "            self.modelConfig.iterAlphaJump.append([])\n",
        "            self.modelConfig.alphaJumpVals.append([])\n",
        "\n",
        "            if nJumpScale[scale] == 0:\n",
        "                self.modelConfig.iterAlphaJump[-1].append(0)\n",
        "                self.modelConfig.alphaJumpVals[-1].append(0.0)\n",
        "                continue\n",
        "\n",
        "            diffJump = 1.0 / float(nJumpScale[scale])\n",
        "            currVal = 1.0\n",
        "            currIter = 0\n",
        "\n",
        "            while currVal > 0:\n",
        "\n",
        "                self.modelConfig.iterAlphaJump[-1].append(currIter)\n",
        "                self.modelConfig.alphaJumpVals[-1].append(currVal)\n",
        "\n",
        "                currIter += sizeJumpScale[scale]\n",
        "                currVal -= diffJump\n",
        "\n",
        "            self.modelConfig.iterAlphaJump[-1].append(currIter)\n",
        "            self.modelConfig.alphaJumpVals[-1].append(0.0)"
      ],
      "metadata": {
        "id": "DXcTawPxg07k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def addScale(self, depthNewScale):\n",
        "        r\"\"\"\n",
        "        Add a new scale to the model. The output resolution becomes twice\n",
        "        bigger.\n",
        "        \"\"\"\n",
        "        self.netG = self.getOriginalG()\n",
        "        self.netD = self.getOriginalD()\n",
        "\n",
        "        self.netG.addScale(depthNewScale)\n",
        "        self.netD.addScale(depthNewScale)\n",
        "\n",
        "        self.config.depthOtherScales.append(depthNewScale)\n",
        "\n",
        "        self.updateSolversDevice()\n",
        "\n",
        "    def updateAlpha(self, newAlpha):\n",
        "        r\"\"\"\n",
        "        Update the blending factor alpha.\n",
        "        Args:\n",
        "            - alpha (float): blending factor (in [0,1]). 0 means only the\n",
        "                             highest resolution in considered (no blend), 1\n",
        "                             means the highest resolution is fully discarded.\n",
        "        \"\"\"\n",
        "        print(\"Changing alpha to %.3f\" % newAlpha)\n",
        "\n",
        "        self.getOriginalG().setNewAlpha(newAlpha)\n",
        "        self.getOriginalD().setNewAlpha(newAlpha)\n",
        "\n",
        "        if self.avgG:\n",
        "            self.avgG.module.setNewAlpha(newAlpha)\n",
        "\n",
        "        self.config.alpha = newAlpha"
      ],
      "metadata": {
        "id": "ROkIfULa8e-6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}