{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review: Improved Training of Wasserstein GANs\n",
    "\n",
    "###### ***Author***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Contribution\n",
    "\n",
    "- critic weight clipping의 문제점을 toy dataset을 통해서 보였다.\n",
    "- gradient penalty를 제안해서 위의 문제를 해결했다.\n",
    "- 다양한 GAN 구조에 대해 안정적인 학습을 증명하고, weight clipping에 대한 성능 향상, high quality image generation 등이 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Background & Difficulties with weight constraints\n",
    "\n",
    "#### A. Background\n",
    "\n",
    "\n",
    "<img style=\"display: block; margin: auto;\"\n",
    "src=\"https://user-images.githubusercontent.com/68529301/165379661-bd34fa9b-6e08-4f7a-992c-0808f69839b6.png\" alt=\"2\" width=\"600px\" />\n",
    "<p style=\"text-align: center;\">\n",
    "Fig1. Proposition1\n",
    "</p>\n",
    "\n",
    "<img style=\"display: block; margin: auto;\"\n",
    "src=\"https://user-images.githubusercontent.com/68529301/165379678-79569b92-84a8-4fe5-93ad-993d6fbbf4b8.png\" alt=\"2\" width=\"400px\" />\n",
    "<p style=\"text-align: center;\">\n",
    "Fig2\n",
    "</p>\n",
    "\n",
    "<img style=\"display: block; margin: auto;\"\n",
    "src=\"https://user-images.githubusercontent.com/68529301/165379682-b07f66d7-5a84-4a28-b526-320ef27d4608.png\" alt=\"2\" width=\"350px\" />\n",
    "<p style=\"text-align: center;\">\n",
    "Fig3\n",
    "</p>\n",
    "\n",
    "<img style=\"display: block; margin: auto;\"\n",
    "src=\"https://user-images.githubusercontent.com/68529301/165379684-63010cfa-e135-44bb-a374-8c321f178f39.png\" alt=\"2\" width=\"300px\" />\n",
    "<p style=\"text-align: center;\">\n",
    "Fig4\n",
    "</p>\n",
    "\n",
    "WGAN 손실함수(Fig2)을 max로 만드는 f를 f\\*라고 하자. 이 f\\*는 Fig3를 통해서 구할 수 있다. \n",
    "\n",
    "$x$ \\~$P_g$, $y$\\~$P_r$로 샘플링을 해서 $x$와 $y$를 보간한 직선 중 $x$와 $y$ 사이의 점 $x_t$가 있다고 할 때, $x_t=tx+(1-t)y$ 로 나타낼 수 있다. (0 ≤ $t$ ≤ 1)\n",
    "\n",
    "이때, 어떠한 $x_t$이든 Fig4이 만족된다. (증명은 appendix)\n",
    "\n",
    "<img style=\"display: block; margin: auto;\"\n",
    "src=\"https://user-images.githubusercontent.com/68529301/165379686-ea77e61a-74a4-485e-bed3-7c09c058fb1b.png\" alt=\"2\" width=\"500px\" />\n",
    "<p style=\"text-align: center;\">\n",
    "Fig5\n",
    "</p>\n",
    "\n",
    "### B. Weight Clipping의 문제점\n",
    "\n",
    "- weight clipping: 업데이트된 weight를 특정 구간으로 제한하는 것 → 1-Lipschitz를 만족시키기 위함\n",
    "- weight clippping이 최적화에 문제를 발생시킨다. optimization이 성공했을때조차 critic이 pathological value surface를 가지는 경우도 있다.\n",
    "\n",
    "<img style=\"display: block; margin: auto;\"\n",
    "src=\"https://user-images.githubusercontent.com/68529301/165379691-dbfc8dbe-2445-4022-9853-de05f036ef98.png\" alt=\"2\" width=\"500px\" />\n",
    "<p style=\"text-align: center;\">\n",
    "Fig6. 윗줄(weight clipping): 데이터 분포의 higher moments를 잡아내는 데 실패했다. // 밑줄(gradient panelty)\n",
    "</p>\n",
    "\n",
    "<img style=\"display: block; margin: auto;\"\n",
    "src=\"https://user-images.githubusercontent.com/68529301/165379692-6eec3444-0851-4cc2-bbb4-82f808c8d4dc.png\" alt=\"2\" width=\"300px\" />\n",
    "<p style=\"text-align: center;\">\n",
    "Fig7. Swiss Roll dataset을 학습시키는 도중 weight clipping을 사용할 때, 발생하는 vanish / explode를 보여주고 gradient penalty를 사용 시 문제가 발생하지 않는 것을 보여주는 gradient norm\n",
    "</p>\n",
    "\n",
    "<img style=\"display: block; margin: auto;\"\n",
    "src=\"https://user-images.githubusercontent.com/68529301/165379693-389b4474-4854-4bc0-bf5c-8ca20016e014.png\" alt=\"2\" width=\"200px\" />\n",
    "<p style=\"text-align: center;\">\n",
    "Fig8. weight clipping은 가중치가 clipping boundary 근처로 몰리지만 gradient panelty는 그렇지 않는 것을 알 수 있다.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Panelty\n",
    "\n",
    "## A. gradient panelty\n",
    "\n",
    "<img style=\"display: block; margin: auto;\"\n",
    "src=\"https://user-images.githubusercontent.com/68529301/165379696-b8bcb12b-4adf-44be-8ce5-b4759baa562b.png\" alt=\"2\" width=\"600px\" />\n",
    "<p style=\"text-align: center;\">\n",
    "Fig9\n",
    "</p>\n",
    "\n",
    "- gradient의 norm이 항상 1보다 작으면, 미분 가능한 함수는 1-Libschtiz를 만족한다.\n",
    "- 이 내용을 사용해서, critic의 output의 gradient norm을 제한함.\n",
    "\n",
    "## B. Sampling distribution\n",
    "\n",
    "- 데이터 분포 $P_r$과 generator 분포 $P_g$에서 뽑은 sample 사이를 이은 직선에서 $\\hat{x}$을 sampling하여 사용하였다.\n",
    "- 이는 최적의 critic이 $P_r, P_g$로부터의 점들을 연결하는 gradient norm 1의 직선을 가지고 있다는 점에서 motivation을 받았다.\n",
    "- 모든 곳에서 gradient norm constraint를 주는 것은 어렵기 때문에, 이렇게 직선을 따라 하는 것도 실험적으로 좋은 성능을 보였다.\n",
    "\n",
    "## C. Penalty coefficient\n",
    "\n",
    "- 전체 실험에 대해서 $\\lambda$=10을 사용함. (toy task, ImageNet CNN까지 잘 된다)\n",
    "\n",
    "## D. No critic batch normalization\n",
    "\n",
    "- 대부분의 GAN은 batch normalization을 discriminator와 generator 둘다에 적용해서 학습을 안정화시키려했지만, batch normalization은 discriminator의 단일 입력을 단일 출력으로 매핑하는 문제로부터, 입력의 전체 배치로부터 출력의 배치로 매핑하는 문제로 유형을 변화시킨다.\n",
    "- 기존처럼 전체 batch를 penalize하는 것이라 아니라 각 input에 독립적으로 critic의 gradient norm을 penalize 시키기 때문에, batch normalization은 wgan gp에 맞지 않는다.\n",
    "- 그래서 batch normalizaiton을 생략하고 훈련을 진행하였으며, 또한 batch normalization보다는 layer normalization을 사용하는 것을 추천한다.\n",
    "\n",
    "## E. Two-sided penalty\n",
    "\n",
    "- **One-sided penalty**\n",
    "    \n",
    "<img style=\"display: block; margin: auto;\"\n",
    "src=\"https://user-images.githubusercontent.com/68529301/165379699-94b95fee-aafd-449e-84a1-a49fb765c946.png\" alt=\"2\" width=\"600px\" />\n",
    "<p style=\"text-align: center;\">\n",
    "Fig10\n",
    "</p>\n",
    "    \n",
    "- **Two-sided penalty**\n",
    "    \n",
    "<img style=\"display: block; margin: auto;\"\n",
    "src=\"https://user-images.githubusercontent.com/68529301/165379701-a094b806-ca24-4ff2-9325-fe7019ba8816.png\" alt=\"2\" width=\"600px\" />\n",
    "<p style=\"text-align: center;\">\n",
    "Fig11\n",
    "</p>\n",
    "    \n",
    "- gradient norm이 1 이하가 되도록 (one-sided penalty)하는 것보다 1로 향하도록 (two-sided penalty)를 촉진한다.\n",
    "- one-sided penalty가 더 좋은 경우도 있고 two-sided penalty가 더 좋은 경우도 있다.\n",
    "- 그럼에도 two-sided penalty를 사용한 이유는 언급되어 있지 않고 후속 연구로 넘겨버렸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Experiments\n",
    "\n",
    "## A. training random architectures within a set\n",
    "\n",
    "- 200개의 아키텍처를 standard GAN, WGAN-GP로 각각 학습시키고 점수를 비교함\n",
    "- 기준: inception_score > min_score\n",
    "    \n",
    "<img style=\"display: block; margin: auto;\"\n",
    "src=\"https://user-images.githubusercontent.com/68529301/165379703-f7fbea91-3881-4857-ad5e-01bcbcfcca1a.png\" alt=\"2\" width=\"600px\" />\n",
    "<p style=\"text-align: center;\">\n",
    "Fig12\n",
    "</p>\n",
    "    \n",
    "\n",
    "## B. LSUN bedroom dataset\n",
    "\n",
    "- WGAN-GP는 batch normalization 대신 layer normalization을 사용하였다.\n",
    "- WGAN-GP를 제외한 모델들은 불안정하거나 mode collapse에 빠진 모습을 볼 수 있다.\n",
    "    \n",
    "<img style=\"display: block; margin: auto;\"\n",
    "src=\"https://user-images.githubusercontent.com/68529301/165379708-6fe0f980-6dec-4f10-a4c1-3218757bdeac.png\" alt=\"2\" width=\"600px\" />\n",
    "<p style=\"text-align: center;\">\n",
    "Fig13\n",
    "</p>\n",
    "    \n",
    "    \n",
    "\n",
    "## C. Improved performance over weight clipping\n",
    "\n",
    "- weight clipping보다 학습 속도가 빠르고 sample quality가 좋아졌음을 증명\n",
    "- 아래의 plot을 보면 weight clipping 보다 converge 속도도 빠르고 성능도 좋다는 것을 알 수 있다.\n",
    "- weight clipping은 RMSProp optimizer를 사용하였다.\n",
    "- WGAN-GP에 Adam optimizer를 적용했는데 성능이 더 좋았다.\n",
    "- DCGAN보다 속도는 느리지만 converge 되었을때 score가 더 안정적이다.\n",
    "    \n",
    "<img style=\"display: block; margin: auto;\"\n",
    "src=\"https://user-images.githubusercontent.com/68529301/165379712-fd94f51f-6daa-4bd1-8856-7ece6fb09432.png\" alt=\"2\" width=\"600px\" />\n",
    "<p style=\"text-align: center;\">\n",
    "Fig14\n",
    "</p>\n",
    "    \n",
    "\n",
    "## D. Sample quality on CIFAR-10 and LSUN bedrooms\n",
    "\n",
    "- unsupervised model은  SOTA, supervised model은 SGAN을 제외한 다른 GAN들보다 성능이 우수했다.\n",
    "    \n",
    "<img style=\"display: block; margin: auto;\"\n",
    "src=\"https://user-images.githubusercontent.com/68529301/165379715-e203f98d-5b97-45c4-a0a7-ea18461a7d0b.png\" alt=\"2\" width=\"600px\" />\n",
    "<p style=\"text-align: center;\">\n",
    "Fig15\n",
    "</p>\n",
    "\n",
    "    \n",
    "\n",
    "## E. Modeling discrete data with a continuous generator\n",
    "\n",
    "## F. meaningful loss curves and detecting overfitting\n",
    "\n",
    "<img style=\"display: block; margin: auto;\"\n",
    "src=\"https://user-images.githubusercontent.com/68529301/165379718-88870f71-72a2-4b4e-918c-a2b0d290131e.png\" alt=\"2\" width=\"600px\" />\n",
    "<p style=\"text-align: center;\">\n",
    "Fig16\n",
    "</p>\n",
    "\n",
    "- weight clipping의 장점이 loss가 sample quality와 상관 관계가 있고 minimum으로 수렴한다는 데에 있다.\n",
    "- gradient panelty도 plot을 확인했을 때, genreator가 $W(P_r, P_g)$를 최소화하면서 loss가 수렴한다는 것을 알 수 있다.\n",
    "- WGAN-GP는 critic에서의 과적합을 탐지하고 네트워크가 최소화하는 동일한 loss에 대해 과적합을 측정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Implementation\n",
    "\n",
    "<img style=\"display: block; margin: auto;\"\n",
    "src=\"https://user-images.githubusercontent.com/68529301/165379721-5848cd13-e363-433f-a3bc-6cebd2b1216b.png\" alt=\"2\" width=\"600px\" />\n",
    "<p style=\"text-align: center;\">\n",
    "Fig17\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "\n",
    "    return gradient_penalty"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
